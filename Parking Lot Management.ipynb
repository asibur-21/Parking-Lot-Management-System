{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f22ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install ultralytics opencv-python-headless matplotlib -q\n",
    "\n",
    "\n",
    "# Import libraries\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow  # For displaying images in Colab\n",
    "\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "\n",
    "# Upload/Load Video\n",
    "from google.colab import files\n",
    "uploaded = files.upload()  # Upload a video file (e.g., parking.mp4)\n",
    "\n",
    "video_path = list(uploaded.keys())[0]  # First uploaded file\n",
    "\n",
    "\n",
    "# Define parking spaces\n",
    "parking_spaces = [\n",
    "    (100, 200, 80, 150),\n",
    "    (200, 200, 80, 150),\n",
    "    (300, 200, 80, 150)\n",
    "]\n",
    "\n",
    "\n",
    "# Process video (Colab compatible)\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "# Get video properties\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "\n",
    "# Define video writer (to save output) - using MP4V codec which works better in Colab\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(\"output.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "\n",
    "# Create a summary display panel\n",
    "summary_height = 100\n",
    "summary_width = width\n",
    "\n",
    "\n",
    "# Process the video\n",
    "frame_count = 0\n",
    "output_frames = []  # To store frames for display\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    # Process only every nth frame to speed up processing\n",
    "    if frame_count % 5 != 0:\n",
    "        continue\n",
    "\n",
    "    # Create a summary display at the bottom\n",
    "    summary_display = np.zeros((summary_height, summary_width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Run YOLOv8 inference\n",
    "    results = model(frame, verbose=False)\n",
    "    detections = results[0].boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2]\n",
    "\n",
    "    # Initialize counters\n",
    "    occupied_count = 0\n",
    "    vacant_count = 0\n",
    "\n",
    "    # Check each parking space\n",
    "    for idx, (x, y, w, h) in enumerate(parking_spaces):\n",
    "        roi = (x, y, x + w, y + h)\n",
    "        status = \"Vacant\"\n",
    "\n",
    "        # Check overlap with detected cars\n",
    "        for det in detections:\n",
    "            x1, y1, x2, y2 = det[:4]\n",
    "            box = (int(x1), int(y1), int(x2), int(y2))\n",
    "\n",
    "            # Calculate overlap (intersection area)\n",
    "            overlap_x1 = max(roi[0], box[0])\n",
    "            overlap_y1 = max(roi[1], box[1])\n",
    "            overlap_x2 = min(roi[2], box[2])\n",
    "            overlap_y2 = min(roi[3], box[3])\n",
    "\n",
    "            if overlap_x1 < overlap_x2 and overlap_y1 < overlap_y2:\n",
    "                status = \"Occupied\"\n",
    "                break\n",
    "\n",
    "        # Update counters\n",
    "        if status == \"Occupied\":\n",
    "            occupied_count += 1\n",
    "        else:\n",
    "            vacant_count += 1\n",
    "\n",
    "        # Draw parking slot\n",
    "        color = (0, 255, 0) if status == \"Vacant\" else (0, 0, 255)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(frame, f\"Slot {idx+1}: {status}\", (x, y - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    # Add summary information to the display\n",
    "    cv2.putText(summary_display, f\"Occupied: {occupied_count}\", (50, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "    cv2.putText(summary_display, f\"Vacant: {vacant_count}\", (50, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "    # Add a visual indicator for each parking space in the summary\n",
    "    slot_width = summary_width // len(parking_spaces)\n",
    "    for idx, (x, y, w, h) in enumerate(parking_spaces):\n",
    "        # Check if this slot is occupied\n",
    "        status = \"Vacant\"\n",
    "        roi = (x, y, x + w, y + h)\n",
    "        for det in detections:\n",
    "            x1, y1, x2, y2 = det[:4]\n",
    "            box = (int(x1), int(y1), int(x2), int(y2))\n",
    "\n",
    "            overlap_x1 = max(roi[0], box[0])\n",
    "            overlap_y1 = max(roi[1], box[1])\n",
    "            overlap_x2 = min(roi[2], box[2])\n",
    "            overlap_y2 = min(roi[3], box[3])\n",
    "\n",
    "            if overlap_x1 < overlap_x2 and overlap_y1 < overlap_y2:\n",
    "                status = \"Occupied\"\n",
    "                break\n",
    "\n",
    "        # Draw the indicator\n",
    "        color = (0, 255, 0) if status == \"Vacant\" else (0, 0, 255)\n",
    "        cv2.rectangle(summary_display,\n",
    "                     (idx * slot_width + 10, 10),\n",
    "                     ((idx + 1) * slot_width - 10, 90),\n",
    "                     color, -1)\n",
    "        cv2.putText(summary_display, str(idx+1),\n",
    "                   (idx * slot_width + slot_width//2 - 10, 55),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "    # Combine the frame with the summary display\n",
    "    combined_frame = np.vstack((frame, summary_display))\n",
    "\n",
    "    out.write(combined_frame)\n",
    "\n",
    "    # Store every 30th frame for display\n",
    "    if frame_count % 30 == 0:\n",
    "        output_frames.append(combined_frame.copy())\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(\"âœ… Processing complete! The output video is saved as output.mp4\")\n",
    "\n",
    "\n",
    "# Display sample frames\n",
    "print(\"Displaying sample frames...\")\n",
    "for i, frame in enumerate(output_frames[:3]):  # Show first 3 stored frames\n",
    "    print(f\"Frame {i+1}:\")\n",
    "    # Convert BGR to RGB for matplotlib\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Download output video\n",
    "from google.colab import files\n",
    "files.download(\"output.mp4\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
